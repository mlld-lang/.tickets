---
id: m-3662
status: open
deps: []
links: [m-dce3]
created: 2026-02-09T06:19:30Z
type: feature
priority: 2
assignee: Adam Avenir
tags: [security, needs-human-design, module]
---
# Design: Schema validation guards (@mlld/guards/schema)

## Task

Design a standard guard module for schema validation at trust boundaries. This is a DESIGN task — produce a module spec, not an implementation.

## Layer

Standard library module (@mlld/guards/schema), NOT core engine. Schema validation is orthogonal to taint/flow — it's about data SHAPE, not data FLOW. mlld's existing guard primitive is expressive enough; this is a well-designed module on top of it.

## Problem

Schema validation at trust boundaries is the single most adopted defensive technique across all 18 AI agent repos studied (12+ repos). Pydantic, JSON Schema, Zod — validating the structure of data at every boundary. mlld's security model focuses on flow (where data can go) but not shape (whether data is well-formed). A malformed-but-untainted LLM response that passes flow checks can still cause downstream failures.

LLM output type confusion (list vs dict, missing fields, wrong types) is the most common failure mode across langchain, llama_index, AutoGPT, autogen, and crewAI.

## Evidence

30+ input validation patterns across all repos. 9+ repos have explicit LLM output validation patterns. The pattern is universal: validate structure at every trust boundary, fail fast on malformed data.

## Design Questions

1. **Schema format** — JSON Schema? A mlld-native schema syntax? Both? JSON Schema has broad tooling support. A native syntax could be more concise and integrate with labels.
2. **Guard integration** — How does a schema guard compose with the guard system? Strawman:
   ```mlld
   import { @schemaGuard } from "@mlld/guards/schema"
   guard @validateOutput after llm = @schemaGuard("./schemas/output.json")
   ```
3. **Policy sugar** — Should policy support declarative schema binding? E.g.:
   ```mlld
   policy {
     schemas: {
       "after:exe:llm:*": "./schemas/llm-output.json"
     }
   }
   ```
   This would auto-generate guards, similar to how autosign/autoverify work.
4. **Label integration** — Should passing schema validation add a label (e.g., `schema:valid` or `schema:output-v1`)? This lets downstream policy rules say "only schema-validated data can reach the database."
5. **Failure behavior** — Deny the operation? Return a default? Retry with a correction prompt? Should the guard support configurable failure strategies?
6. **Partial validation** — LLM output is often almost-right (extra fields, slightly wrong types). Should the guard support coercion/normalization in addition to strict validation?
7. **Schema per exe** — Different LLM exes produce different shapes. How does the module handle schema-per-function binding ergonomically?

## Deliverable

Module API spec: exports, guard signatures, policy integration syntax, label semantics, and failure modes.

